{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification -> Pytorch\n",
    "- Target\n",
    "    1. build up sample RNN (construct layer)\n",
    "    2. optimize RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = torch.ones(100,2)         # data base numbers 100x2 matrix \n",
    "\n",
    "x0 = torch.normal(2*n_data , 1)    # data point [zero cluster], normal(mean , std)     shape=(100,2)\n",
    "y0 = torch.zeros(100)              # label      [zero cluster]                         shape=(100,1)\n",
    "\n",
    "x1 = torch.normal(-2*n_data , 1)   # data point [ones cluster], normal(mean , std)     shape=(100,2)\n",
    "y1 = torch.ones(100)               # label      [ones cluster]                         shape=(100,1)\n",
    "\n",
    "# concat x data point \n",
    "x = torch.cat((x0 , x1) , 0).type(torch.FloatTensor)    # FloatTensor = 32-bit         shape=(200,2)\n",
    "y = torch.cat((y0 , y1) , ).type(torch.LongTensor)      # LongTensor  = 64-bit integer shape=(200,1) (label 一定是要是 LongTensor format) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Classification Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=2, out_features=10, bias=True)\n",
      "  (predict): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Net inherit torch.nn.Module\n",
    "class Net(torch.nn.Module):\n",
    "    # 定義 layer function (hidden)\n",
    "    # n_feature -> 數據個數 , n_hidden -> hidden layer 神經元個數 , n_output -> output個數\n",
    "    def __init__(self , n_feature , n_hidden , n_output):\n",
    "        super(Net,self).__init__()\n",
    "        # define hidden layer -> Linear function (numbers of input , numbers of output)\n",
    "        # hidden layer = function(n_input , n_output)\n",
    "        self.hidden =  torch.nn.Linear(n_feature , n_hidden)\n",
    "        # output layer = function(n_input , n_output)\n",
    "        self.predict = torch.nn.Linear(n_hidden , n_output)\n",
    "\n",
    "    # 向前傳遞 -> 拿Layer來£用\n",
    "    # x -> data\n",
    "    def forward(self ,x):\n",
    "        # Activated Function [F.relu] ( hidden layer(x[n_feature]) ) -> n_hidden\n",
    "        x = F.relu(self.hidden(x))\n",
    "        # self.predict(x[n_hidden]) -> n_output\n",
    "        x = self.predict(x)\n",
    "        return x   \n",
    "\n",
    "# feature (x,y) -> input == 2 , output == 2\n",
    "net = Net(2,10,2)   \n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.optim.{optimizer}({parameter})\n",
    "# 優化神經網絡參數 -> 傳入神經網絡參數 , learning_rate \n",
    "optimizer = torch.optim.SGD(net.parameters() , lr=0.02)\n",
    "\n",
    "# loss_function (CrossEntropyLoss 多分類 Loss_func problem)\n",
    "loss_func = torch.nn.CrossEntropyLoss()   # 概率 [0.1 ,0.2 ,0.7] -> 相加 == 1 , 第三個分類最有機會\n",
    "\n",
    "for t in range(100):\n",
    "    out = net(x)\n",
    "\n",
    "    #loss_func(prediction , real_value) \n",
    "    loss = loss_func(out , y)\n",
    "\n",
    "    # 先把神經網絡裡面的參數的梯度 -> 0\n",
    "    optimizer.zero_grad()\n",
    "    # 誤差反向傳遞 loss => Variable (傳遞給每個節點這次計算出來的梯度)\n",
    "    loss.backward()\n",
    "    # 透過 optimizer 優化這些梯度\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7ff03e8f717581f4d2be2080033f8219cf68bd655ee8df80f9e504f30ffcd41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
