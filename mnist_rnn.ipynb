{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural network \n",
    "- >Image classification\n",
    "    -  split traindata and testdata\n",
    "    -  put train/test data to Dataloader(shuffle,batch_size,num_workers) respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 10                #全部data訓練10次\n",
    "BATCH_SIZE = 16           #每次訓練隨機丟50張圖像進去\n",
    "LR =0.001                 #learning rate\n",
    "DOWNLOAD_MNIST = True    #第一次用要先下載data,所以是True\n",
    "if_use_gpu = 1            #使用gpu\n",
    "steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    #把灰階從0~255壓縮到0~1\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    #把灰階從0~255壓縮到0~1\n",
    "    download=DOWNLOAD_MNIST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor dataset , Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/changshengchang/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/Users/changshengchang/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(train_data.data.view(-1 , 784).to(torch.float32) , train_data.train_labels)\n",
    "train_loader = DataLoader(train_dataset , shuffle=True , batch_size = BATCH_SIZE , num_workers= 2)\n",
    "\n",
    "test_dataset = TensorDataset(test_data.data.view(-1 , 784).to(torch.float32) , test_data.test_labels)\n",
    "test_loader = DataLoader(train_dataset , shuffle=True , batch_size = BATCH_SIZE , num_workers= 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net ,self).__init__()\n",
    "        self.conv1 = nn.Linear(784 , 128)\n",
    "        self.conv2 = nn.Linear(128 ,256)\n",
    "        self.out = nn.Linear(256 , 10)\n",
    "\n",
    "    def forward(self ,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "def fit(steps , model , train_loader ,opt , loss_func):\n",
    "    for step in range(steps):\n",
    "        model.train()\n",
    "        for b_x , b_y in train_loader:\n",
    "            prediction = model(b_x)\n",
    "            loss = loss_func(prediction , b_y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if step % 10 == 0:   \n",
    "            print('step -> ', loss)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step ->  tensor(0.3095, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(0.0005, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(0.0013, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(2.4761e-05, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(0.0001, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(1.4424e-05, grad_fn=<NllLossBackward0>)\n",
      "step ->  tensor(3.7321e-05, grad_fn=<NllLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [134], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model , torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD( model\u001b[38;5;241m.\u001b[39mparameters() , lr\u001b[38;5;241m=\u001b[39mLR) , \n\u001b[1;32m      7\u001b[0m model , opt  \u001b[38;5;241m=\u001b[39m get_model()\n\u001b[0;32m----> 9\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [133], line 5\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(steps, model, train_loader, opt, loss_func)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(steps):\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m b_x , b_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      6\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m model(b_x)\n\u001b[1;32m      7\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss_func(prediction , b_y)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1357\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1356\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1357\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1358\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1359\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1360\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1323\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1322\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1323\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1324\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1325\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1161\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1149\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1161\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1162\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1163\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1164\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rlock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[39m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39;49mloads(res)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/torch/lib/python3.9/site-packages/torch/multiprocessing/reductions.py:317\u001b[0m, in \u001b[0;36mrebuild_storage_filename\u001b[0;34m(cls, manager, handle, size, dtype)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m         os\u001b[39m.\u001b[39mclose(fd)\n\u001b[0;32m--> 317\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrebuild_storage_filename\u001b[39m(\u001b[39mcls\u001b[39m, manager, handle, size, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    318\u001b[0m     storage: Union[torch\u001b[39m.\u001b[39mTypedStorage, torch\u001b[39m.\u001b[39mUntypedStorage] \u001b[39m=\u001b[39m storage_from_cache(\u001b[39mcls\u001b[39m, handle)\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m storage \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = Net()\n",
    "    return model , torch.optim.SGD( model.parameters() , lr=LR) , \n",
    "\n",
    "\n",
    "\n",
    "model , opt  = get_model()\n",
    "\n",
    "fit(steps,model , train_loader,opt,loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7ff03e8f717581f4d2be2080033f8219cf68bd655ee8df80f9e504f30ffcd41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
