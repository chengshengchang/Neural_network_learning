{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer \n",
    "\n",
    "        - 降低 Loss\n",
    "        \n",
    "        - 提升訓練效率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyper parameters\n",
    "LR = 0.01\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 12\n",
    "\n",
    "x = torch.unsqueeze(torch.linspace(-1, 1, 1000), dim=1)\n",
    "y = x.pow(2) + 0.1*torch.normal(torch.zeros(*x.size()))\n",
    "\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x,y)\n",
    "\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build default net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net inherit torch.nn.Module\n",
    "class Net(torch.nn.Module):\n",
    "    # 定義 layer function (hidden)\n",
    "    # n_feature -> 數據個數 , n_hidden -> hidden layer 神經元個數 , n_output -> output個數\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # define hidden layer -> Linear function (numbers of input , numbers of output)\n",
    "        # hidden layer = function(n_input , n_output)\n",
    "        self.hidden =  torch.nn.Linear(1,20)\n",
    "        # output layer = function(n_input , n_output)\n",
    "        self.predict = torch.nn.Linear(20,1)\n",
    "\n",
    "    # 向前傳遞 -> 拿Layer來用\n",
    "    # x -> data\n",
    "    def forward(self ,x):\n",
    "        # Activated Function [F.relu] ( hidden layer(x[n_feature]) ) -> n_hidden\n",
    "        x = F.relu(self.hidden(x))\n",
    "        # self.predict(x[n_hidden]) -> n_output\n",
    "        x = self.predict(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# 建立四個神經網絡並用不同 optimizer 去優化神經網路\n",
    "net_SGD =       Net()\n",
    "net_Momentum =  Net()\n",
    "net_RMSprop =   Net()\n",
    "net_Adam =      Net()\n",
    "\n",
    "# Network list\n",
    "nets = [net_SGD, net_Momentum, net_RMSprop, net_Adam]\n",
    " \n",
    "# 分別建立不同optimizer 並設定parameters\n",
    "opt_SGD =      torch.optim.SGD(net_SGD.parameters(), lr=LR)\n",
    "opt_Momentum = torch.optim.SGD(net_Momentum.parameters(), lr=LR, momentum=0.8)\n",
    "opt_RMSprop =  torch.optim.RMSprop(net_RMSprop.parameters(), lr=LR, alpha=0.9)\n",
    "opt_Adam =     torch.optim.Adam(net_Adam.parameters(), lr=LR, betas=(0.9, 0.99))\n",
    "\n",
    "# Optimizer list\n",
    "optimizers = [opt_SGD, opt_Momentum, opt_RMSprop, opt_Adam]\n",
    "\n",
    "# Regression loss function\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "# Record every optimizer loss to 2x2 matrix\n",
    "loss_history = [[],[],[],[]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to train\n",
    "- zip(nets , optimizer , loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print(epoch)\n",
    "    for step , (batch_x,batch_y) in enumerate(loader):\n",
    "        b_x  , b_y = Variable(batch_x) , Variable(batch_y)\n",
    "\n",
    "        for net , opt , l_his in zip(nets , optimizers , loss_history):\n",
    "            output = net(b_x)                       # get output for every net\n",
    "            loss = loss_func(output, b_y)       # 計算誤差 compute loss for every net\n",
    "            opt.zero_grad()                         # 清空梯度 clear gradient for next train\n",
    "            loss.backward()                         # 誤差反向傳播 (loss propagation , compute gradirent)\n",
    "            opt.step()                              # apply gradient \n",
    "            l_his.append(loss)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7ff03e8f717581f4d2be2080033f8219cf68bd655ee8df80f9e504f30ffcd41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
